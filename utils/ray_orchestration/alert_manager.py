"""
Alert Manager with Rules Engine

Provides a flexible alerting system with configurable rules
for job failures, resource thresholds, and custom conditions.
"""

import logging
import threading
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum, auto
from typing import Optional, Dict, Any, List, Callable, Union
from uuid import UUID, uuid4

from models.job import Job, JobState

logger = logging.getLogger(__name__)


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = auto()
    WARNING = auto()
    ERROR = auto()
    CRITICAL = auto()


class AlertCategory(Enum):
    """Alert categories."""
    JOB = auto()           # Job-related alerts
    RESOURCE = auto()      # Resource threshold alerts
    PERFORMANCE = auto()   # Performance degradation
    SYSTEM = auto()        # System-level alerts


@dataclass
class Alert:
    """
    An alert generated by the system.

    Attributes
    ----------
    id : UUID
        Unique alert identifier
    timestamp : datetime
        When alert was generated
    severity : AlertSeverity
        Alert severity level
    category : AlertCategory
        Alert category
    title : str
        Short alert title
    message : str
        Detailed alert message
    source : str
        Source of the alert (rule name, component, etc.)
    data : dict
        Additional context data
    acknowledged : bool
        Whether alert has been acknowledged
    """

    severity: AlertSeverity
    category: AlertCategory
    title: str
    message: str
    source: str = ""
    id: UUID = field(default_factory=uuid4)
    timestamp: datetime = field(default_factory=datetime.now)
    data: Dict[str, Any] = field(default_factory=dict)
    acknowledged: bool = False

    def acknowledge(self):
        """Mark alert as acknowledged."""
        self.acknowledged = True

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            'id': str(self.id),
            'timestamp': self.timestamp.isoformat(),
            'severity': self.severity.name,
            'category': self.category.name,
            'title': self.title,
            'message': self.message,
            'source': self.source,
            'data': self.data,
            'acknowledged': self.acknowledged,
        }


class AlertRule(ABC):
    """
    Abstract base class for alert rules.

    Subclass this to create custom alert rules.
    """

    def __init__(
        self,
        name: str,
        severity: AlertSeverity = AlertSeverity.WARNING,
        category: AlertCategory = AlertCategory.SYSTEM,
        enabled: bool = True,
        cooldown_seconds: int = 60,
    ):
        """
        Initialize alert rule.

        Parameters
        ----------
        name : str
            Rule name for identification
        severity : AlertSeverity
            Severity of generated alerts
        category : AlertCategory
            Category of generated alerts
        enabled : bool
            Whether rule is enabled
        cooldown_seconds : int
            Minimum time between alerts from this rule
        """
        self.name = name
        self.severity = severity
        self.category = category
        self.enabled = enabled
        self.cooldown_seconds = cooldown_seconds
        self._last_triggered: Optional[datetime] = None

    @abstractmethod
    def evaluate(self, context: Dict[str, Any]) -> Optional[Alert]:
        """
        Evaluate the rule against given context.

        Parameters
        ----------
        context : dict
            Context data for evaluation

        Returns
        -------
        Alert or None
            Alert if triggered, None otherwise
        """
        pass

    def can_trigger(self) -> bool:
        """Check if rule can trigger (respecting cooldown)."""
        if not self.enabled:
            return False

        if self._last_triggered is None:
            return True

        elapsed = (datetime.now() - self._last_triggered).total_seconds()
        return elapsed >= self.cooldown_seconds

    def mark_triggered(self):
        """Mark rule as triggered (for cooldown tracking)."""
        self._last_triggered = datetime.now()


class JobFailureRule(AlertRule):
    """
    Alert rule for job failures.

    Triggers when a job fails with configurable thresholds.
    """

    def __init__(
        self,
        name: str = "Job Failure",
        severity: AlertSeverity = AlertSeverity.ERROR,
        min_failures_threshold: int = 1,
        time_window_minutes: int = 60,
        **kwargs,
    ):
        """
        Initialize job failure rule.

        Parameters
        ----------
        min_failures_threshold : int
            Minimum failures to trigger alert
        time_window_minutes : int
            Time window to count failures
        """
        super().__init__(
            name=name,
            severity=severity,
            category=AlertCategory.JOB,
            **kwargs,
        )
        self.min_failures = min_failures_threshold
        self.time_window = timedelta(minutes=time_window_minutes)
        self._recent_failures: List[datetime] = []

    def evaluate(self, context: Dict[str, Any]) -> Optional[Alert]:
        """Evaluate job failure rule."""
        if not self.can_trigger():
            return None

        job = context.get('job')
        if job is None or job.state != JobState.FAILED:
            return None

        # Track this failure
        now = datetime.now()
        self._recent_failures.append(now)

        # Clean old failures
        cutoff = now - self.time_window
        self._recent_failures = [f for f in self._recent_failures if f > cutoff]

        # Check threshold
        if len(self._recent_failures) >= self.min_failures:
            self.mark_triggered()

            return Alert(
                severity=self.severity,
                category=self.category,
                title=f"Job Failed: {job.name}",
                message=f"Job '{job.name}' failed with error: {job.error_message}",
                source=self.name,
                data={
                    'job_id': str(job.id),
                    'job_name': job.name,
                    'error': job.error_message,
                    'recent_failures': len(self._recent_failures),
                },
            )

        return None


class ConsecutiveFailuresRule(AlertRule):
    """
    Alert rule for consecutive job failures.

    Triggers when N jobs fail in a row.
    """

    def __init__(
        self,
        name: str = "Consecutive Failures",
        severity: AlertSeverity = AlertSeverity.CRITICAL,
        threshold: int = 3,
        **kwargs,
    ):
        """
        Initialize consecutive failures rule.

        Parameters
        ----------
        threshold : int
            Number of consecutive failures to trigger
        """
        super().__init__(
            name=name,
            severity=severity,
            category=AlertCategory.JOB,
            **kwargs,
        )
        self.threshold = threshold
        self._consecutive_count = 0

    def evaluate(self, context: Dict[str, Any]) -> Optional[Alert]:
        """Evaluate consecutive failures rule."""
        if not self.can_trigger():
            return None

        job = context.get('job')
        if job is None:
            return None

        # Track consecutive failures
        if job.state == JobState.FAILED:
            self._consecutive_count += 1
        elif job.state == JobState.COMPLETED:
            self._consecutive_count = 0
            return None
        else:
            return None

        # Check threshold
        if self._consecutive_count >= self.threshold:
            self.mark_triggered()

            return Alert(
                severity=self.severity,
                category=self.category,
                title=f"{self._consecutive_count} Consecutive Job Failures",
                message=f"The last {self._consecutive_count} jobs have failed. "
                        f"Most recent: {job.name}",
                source=self.name,
                data={
                    'consecutive_failures': self._consecutive_count,
                    'last_job_id': str(job.id),
                    'last_job_name': job.name,
                },
            )

        return None


class ErrorRateRule(AlertRule):
    """
    Alert rule for high error rates.

    Triggers when error rate exceeds threshold over time window.
    """

    def __init__(
        self,
        name: str = "High Error Rate",
        severity: AlertSeverity = AlertSeverity.WARNING,
        error_rate_threshold: float = 0.2,  # 20%
        min_jobs: int = 5,
        time_window_minutes: int = 60,
        **kwargs,
    ):
        """
        Initialize error rate rule.

        Parameters
        ----------
        error_rate_threshold : float
            Error rate threshold (0.0-1.0)
        min_jobs : int
            Minimum jobs needed to calculate rate
        time_window_minutes : int
            Time window for rate calculation
        """
        super().__init__(
            name=name,
            severity=severity,
            category=AlertCategory.PERFORMANCE,
            **kwargs,
        )
        self.error_rate_threshold = error_rate_threshold
        self.min_jobs = min_jobs
        self.time_window = timedelta(minutes=time_window_minutes)
        self._job_results: List[tuple] = []  # (datetime, is_success)

    def evaluate(self, context: Dict[str, Any]) -> Optional[Alert]:
        """Evaluate error rate rule."""
        if not self.can_trigger():
            return None

        job = context.get('job')
        if job is None or not job.is_terminal:
            return None

        # Track this result
        now = datetime.now()
        is_success = job.state == JobState.COMPLETED
        self._job_results.append((now, is_success))

        # Clean old results
        cutoff = now - self.time_window
        self._job_results = [(t, s) for t, s in self._job_results if t > cutoff]

        # Need minimum jobs
        if len(self._job_results) < self.min_jobs:
            return None

        # Calculate error rate
        failures = sum(1 for _, success in self._job_results if not success)
        error_rate = failures / len(self._job_results)

        if error_rate >= self.error_rate_threshold:
            self.mark_triggered()

            return Alert(
                severity=self.severity,
                category=self.category,
                title=f"High Error Rate: {error_rate:.1%}",
                message=f"Job error rate of {error_rate:.1%} exceeds threshold of "
                        f"{self.error_rate_threshold:.1%} over the last "
                        f"{int(self.time_window.total_seconds() / 60)} minutes.",
                source=self.name,
                data={
                    'error_rate': error_rate,
                    'threshold': self.error_rate_threshold,
                    'total_jobs': len(self._job_results),
                    'failures': failures,
                },
            )

        return None


class LongRunningJobRule(AlertRule):
    """
    Alert rule for jobs running longer than expected.
    """

    def __init__(
        self,
        name: str = "Long Running Job",
        severity: AlertSeverity = AlertSeverity.WARNING,
        duration_minutes: int = 30,
        **kwargs,
    ):
        """
        Initialize long running job rule.

        Parameters
        ----------
        duration_minutes : int
            Duration threshold in minutes
        """
        super().__init__(
            name=name,
            severity=severity,
            category=AlertCategory.JOB,
            **kwargs,
        )
        self.duration_threshold = timedelta(minutes=duration_minutes)
        self._alerted_jobs: set = set()

    def evaluate(self, context: Dict[str, Any]) -> Optional[Alert]:
        """Evaluate long running job rule."""
        if not self.can_trigger():
            return None

        job = context.get('job')
        if job is None:
            return None

        # Skip if not running or already alerted
        if job.state != JobState.RUNNING:
            self._alerted_jobs.discard(job.id)
            return None

        if job.id in self._alerted_jobs:
            return None

        # Check duration
        if job.started_at is None:
            return None

        duration = datetime.now() - job.started_at
        if duration >= self.duration_threshold:
            self._alerted_jobs.add(job.id)
            self.mark_triggered()

            return Alert(
                severity=self.severity,
                category=self.category,
                title=f"Long Running Job: {job.name}",
                message=f"Job '{job.name}' has been running for "
                        f"{int(duration.total_seconds() / 60)} minutes.",
                source=self.name,
                data={
                    'job_id': str(job.id),
                    'job_name': job.name,
                    'duration_minutes': duration.total_seconds() / 60,
                },
            )

        return None


class AlertManager:
    """
    Central manager for alerts and rules.

    Evaluates rules against events and manages alert lifecycle.

    Usage
    -----
    >>> manager = AlertManager()
    >>> manager.add_rule(JobFailureRule())
    >>> manager.add_rule(ConsecutiveFailuresRule(threshold=3))
    >>>
    >>> # Process events
    >>> manager.process_job_event(failed_job)
    >>>
    >>> # Get active alerts
    >>> alerts = manager.get_alerts()
    """

    def __init__(self, max_alerts: int = 100):
        """
        Initialize alert manager.

        Parameters
        ----------
        max_alerts : int
            Maximum alerts to retain
        """
        self._rules: List[AlertRule] = []
        self._alerts: List[Alert] = []
        self._callbacks: List[Callable[[Alert], None]] = []
        self._max_alerts = max_alerts
        self._lock = threading.Lock()

    def add_rule(self, rule: AlertRule) -> None:
        """Add an alert rule."""
        with self._lock:
            self._rules.append(rule)
        logger.debug(f"Added alert rule: {rule.name}")

    def remove_rule(self, name: str) -> bool:
        """Remove a rule by name."""
        with self._lock:
            for i, rule in enumerate(self._rules):
                if rule.name == name:
                    del self._rules[i]
                    logger.debug(f"Removed alert rule: {name}")
                    return True
        return False

    def get_rules(self) -> List[AlertRule]:
        """Get all rules."""
        with self._lock:
            return list(self._rules)

    def enable_rule(self, name: str) -> bool:
        """Enable a rule by name."""
        with self._lock:
            for rule in self._rules:
                if rule.name == name:
                    rule.enabled = True
                    return True
        return False

    def disable_rule(self, name: str) -> bool:
        """Disable a rule by name."""
        with self._lock:
            for rule in self._rules:
                if rule.name == name:
                    rule.enabled = False
                    return True
        return False

    def register_callback(self, callback: Callable[[Alert], None]) -> None:
        """Register a callback for new alerts."""
        self._callbacks.append(callback)

    def process_job_event(self, job: Job) -> List[Alert]:
        """
        Process a job event through all rules.

        Parameters
        ----------
        job : Job
            Job that triggered the event

        Returns
        -------
        list
            List of alerts generated
        """
        context = {'job': job}
        return self._evaluate_rules(context)

    def process_event(self, context: Dict[str, Any]) -> List[Alert]:
        """
        Process a generic event through all rules.

        Parameters
        ----------
        context : dict
            Event context data

        Returns
        -------
        list
            List of alerts generated
        """
        return self._evaluate_rules(context)

    def _evaluate_rules(self, context: Dict[str, Any]) -> List[Alert]:
        """Evaluate all rules against context."""
        new_alerts = []

        with self._lock:
            for rule in self._rules:
                if not rule.enabled:
                    continue

                try:
                    alert = rule.evaluate(context)
                    if alert:
                        self._add_alert(alert)
                        new_alerts.append(alert)
                except Exception as e:
                    logger.error(f"Error evaluating rule {rule.name}: {e}")

        # Notify callbacks
        for alert in new_alerts:
            for callback in self._callbacks:
                try:
                    callback(alert)
                except Exception as e:
                    logger.error(f"Error in alert callback: {e}")

        return new_alerts

    def _add_alert(self, alert: Alert) -> None:
        """Add an alert to the list."""
        self._alerts.insert(0, alert)

        # Trim to max
        if len(self._alerts) > self._max_alerts:
            self._alerts = self._alerts[:self._max_alerts]

    def get_alerts(
        self,
        severity: Optional[AlertSeverity] = None,
        category: Optional[AlertCategory] = None,
        acknowledged: Optional[bool] = None,
        limit: int = 50,
    ) -> List[Alert]:
        """
        Get alerts with optional filtering.

        Parameters
        ----------
        severity : AlertSeverity, optional
            Filter by severity
        category : AlertCategory, optional
            Filter by category
        acknowledged : bool, optional
            Filter by acknowledgment status
        limit : int
            Maximum alerts to return

        Returns
        -------
        list
            List of alerts
        """
        with self._lock:
            alerts = list(self._alerts)

        if severity is not None:
            alerts = [a for a in alerts if a.severity == severity]

        if category is not None:
            alerts = [a for a in alerts if a.category == category]

        if acknowledged is not None:
            alerts = [a for a in alerts if a.acknowledged == acknowledged]

        return alerts[:limit]

    def get_unacknowledged_count(self) -> int:
        """Get count of unacknowledged alerts."""
        with self._lock:
            return sum(1 for a in self._alerts if not a.acknowledged)

    def acknowledge_alert(self, alert_id: UUID) -> bool:
        """Acknowledge an alert by ID."""
        with self._lock:
            for alert in self._alerts:
                if alert.id == alert_id:
                    alert.acknowledge()
                    return True
        return False

    def acknowledge_all(self) -> int:
        """Acknowledge all alerts."""
        count = 0
        with self._lock:
            for alert in self._alerts:
                if not alert.acknowledged:
                    alert.acknowledge()
                    count += 1
        return count

    def clear_acknowledged(self) -> int:
        """Clear all acknowledged alerts."""
        with self._lock:
            before = len(self._alerts)
            self._alerts = [a for a in self._alerts if not a.acknowledged]
            return before - len(self._alerts)

    def clear_all(self) -> int:
        """Clear all alerts."""
        with self._lock:
            count = len(self._alerts)
            self._alerts = []
            return count


# Singleton instance
_alert_manager: Optional[AlertManager] = None
_manager_lock = threading.Lock()


def get_alert_manager() -> AlertManager:
    """Get or create the singleton AlertManager instance."""
    global _alert_manager

    with _manager_lock:
        if _alert_manager is None:
            _alert_manager = AlertManager()

            # Add default rules
            _alert_manager.add_rule(JobFailureRule())
            _alert_manager.add_rule(ConsecutiveFailuresRule(threshold=3))
            _alert_manager.add_rule(ErrorRateRule(error_rate_threshold=0.2))
            _alert_manager.add_rule(LongRunningJobRule(duration_minutes=30))

        return _alert_manager


def create_default_alert_manager() -> AlertManager:
    """
    Get the singleton AlertManager with default rules.

    This is an alias for get_alert_manager() to ensure singleton pattern.
    The manager is created with default rules on first access.

    Returns
    -------
    AlertManager
        The singleton alert manager instance
    """
    return get_alert_manager()
